{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb646c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7394975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_brackets(input: str) -> str:\n",
    "    text = input[2:-2]\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "CLASSIFICATION_PROMPT = \"\"\"\n",
    "You are an expert AI assistant that is specialized in selecting user preferences.\n",
    "The task it that you are provided with a prompt and two responses (A and B) to that prompt from different LLMs.\n",
    "The possible outcomes are 3 classes:\n",
    "- Winner A: Response A is better\n",
    "- Winner B: Response B is better\n",
    "- Tie: Both responses are equally good\n",
    "\n",
    "The prompt to the models is:\n",
    "```\n",
    "{prompt}\n",
    "```\n",
    "\n",
    "Then response A is:\n",
    "```\n",
    "{response_a}\n",
    "```\n",
    "\n",
    "And response B is:\n",
    "```\n",
    "{response_b}\n",
    "```\n",
    "\n",
    "Based on the above, classify which response is better by choosing one of the following options: \"Winner A\", \"Winner B\", or \"Tie\".\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4eb45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple CSV files\n",
    "df = datasets.load_dataset(\n",
    "    \"csv\", data_files={\"train\": \"../data/train.csv\", \"test\": \"../data/test.csv\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3854c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69048b6ae3bd41c1808f8dd50106bb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-4B-Instruct-2507 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B-Instruct-2507\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Vmpletsos/qwen3-4b-merged-preference-classifier\",\n",
    "    attn_implementation=\"sdpa\",\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d562f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['train'].shuffle().select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb812c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4706914de218430ba11e33d834a192e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fix_dataset(row):\n",
    "    cleaned_prompt = remove_extra_brackets(row[\"prompt\"])\n",
    "    cleaned_response_a = remove_extra_brackets(row[\"response_a\"])\n",
    "    cleaned_response_b = remove_extra_brackets(row[\"response_b\"])\n",
    "\n",
    "    full_prompt = CLASSIFICATION_PROMPT.format(\n",
    "        prompt=cleaned_prompt,\n",
    "        response_a=cleaned_response_a,\n",
    "        response_b=cleaned_response_b,\n",
    "    )\n",
    "\n",
    "    tokenized = tokenizer(full_prompt)\n",
    "\n",
    "    winner = [row[\"winner_model_a\"], row[\"winner_model_b\"], row[\"winner_tie\"]]\n",
    "\n",
    "    return {**tokenized, \"winner\": winner, \"length\": len(tokenized[\"input_ids\"])}\n",
    "\n",
    "df = df.map(fix_dataset, batched=False).remove_columns(\n",
    "    [\n",
    "        \"id\",\n",
    "        \"model_a\",\n",
    "        \"model_b\",\n",
    "        \"prompt\",\n",
    "        \"response_a\",\n",
    "        \"response_b\",\n",
    "        \"winner_model_a\",\n",
    "        \"winner_model_b\",\n",
    "        \"winner_tie\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1e72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_format(\"torch\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "dataloader = DataLoader(\n",
    "    df, batch_size=2, shuffle=False, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a3e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:09<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 60.50%\n",
      "Validation Loss: 0.8676%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "total_count = 0\n",
    "data_size = len(dataloader)\n",
    "for data in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            data = {\n",
    "                key: value.to(\"cuda\") for key, value in data.items()\n",
    "            }\n",
    "            outputs = model(data[\"input_ids\"]).logits\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, true_labels = torch.max(data[\"winner\"], 1)\n",
    "            total_loss += loss_fn(outputs, true_labels).item()\n",
    "            total_count += true_labels.size(0)\n",
    "            total_correct += (predicted == true_labels).sum().item()\n",
    "\n",
    "accuracy = 100 * (total_correct / total_count)\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Validation Loss: {total_loss/data_size:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a78c79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
