{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398da5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import remove_extra_brackets, CLASSIFICATION_PROMPT\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Muon, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn.utils import clip_grad_norm_ as CLIP_GRADIENTS\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b446746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple CSV files\n",
    "df = datasets.load_dataset('csv', data_files={\n",
    "    'train': './data/train.csv',\n",
    "    'test': './data/test.csv'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "print(tokenizer.model_max_length)\n",
    "model_classification = AutoModelForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", num_labels=3)\n",
    "model_classification = model_classification.to(\"cuda\", torch.bfloat16)\n",
    "# model_maskedLM = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd4c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 57477\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202467ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dataset(row):\n",
    "    cleaned_prompt = remove_extra_brackets(row['prompt'])\n",
    "    cleaned_response_a = remove_extra_brackets(row['response_a'])\n",
    "    cleaned_response_b = remove_extra_brackets(row['response_b'])\n",
    "    prompt = CLASSIFICATION_PROMPT.format(\n",
    "        prompt=cleaned_prompt,\n",
    "        response_a=cleaned_response_a,\n",
    "        response_b=cleaned_response_b\n",
    "    )\n",
    "    winner = [row['winner_model_a'], row['winner_model_b'], row['winner_tie']]\n",
    "    return {\n",
    "        \"final_prompt\": prompt,\n",
    "        \"winner\": winner\n",
    "    }\n",
    "    \n",
    "def tokenize_dataset(batch):\n",
    "    tokenized = tokenizer(\n",
    "        batch[\"final_prompt\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22be4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n"
     ]
    }
   ],
   "source": [
    "df = df.map(fix_dataset, batched=False).remove_columns(['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b','winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "df = df.map(tokenize_dataset, batched=True, num_proc=13).remove_columns(['final_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['winner', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 57477\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['winner', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = df['train'].train_test_split(test_size=0.1, seed=42)\n",
    "df['train'] = train_val_split['train']\n",
    "df['validation'] = train_val_split['test']\n",
    "df = df.with_format(\"torch\")\n",
    "train_dataloader = DataLoader(df[\"train\"], batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(df[\"validation\"], batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed61be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['winner', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 51729\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['winner', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['winner', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5748\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = torch.compile(model_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0d37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   3%|▎         | 401/12933 [16:08<512:35:46, 147.25s/it, loss=0.9883]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 35.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   6%|▌         | 800/12933 [23:54<4:03:51,  1.21s/it, loss=1.2949]   "
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model_classification.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "EPOCHS = 10\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "GRADIENT_ACCUMULATION_STEPS = 32\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model_classification.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=True, position=0)\n",
    "    validation_bar = tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False, position=1)\n",
    "    for step, data in enumerate(train_bar):\n",
    "        data = {key: value.to(\"cuda\") for key, value in data.items()}\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            with torch.no_grad():\n",
    "                _, true_labels = torch.max(data[\"winner\"], 1)\n",
    "            \n",
    "            outputs = model_classification(data[\"input_ids\"], attention_mask=data[\"attention_mask\"]).logits\n",
    "            loss = loss_fn(outputs, true_labels)\n",
    "        \n",
    "        (loss / GRADIENT_ACCUMULATION_STEPS).backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_classification.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        if step % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            train_bar.set_postfix({'loss': f\"{(loss.item()):.4f}\"})\n",
    "            \n",
    "        if step % 400 == 0 and step != 0:\n",
    "            model_classification.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for val_data in validation_bar:\n",
    "                    val_data = {key: value.to(\"cuda\") for key, value in val_data.items()}\n",
    "                    outputs = model_classification(val_data[\"input_ids\"], attention_mask=val_data[\"attention_mask\"]).logits\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    _, true_labels = torch.max(val_data[\"winner\"], 1)\n",
    "                    total += true_labels.size(0)\n",
    "                    correct += (predicted == true_labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * (correct / total)\n",
    "            print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "            model_classification.train()\n",
    "    \n",
    "    if (len(train_dataloader) % GRADIENT_ACCUMULATION_STEPS) != 0:\n",
    "        torch.nn.utils.clip_grad_norm_(model_classification.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Avg Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b9549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_preference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
