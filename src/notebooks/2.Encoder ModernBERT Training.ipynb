{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398da5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Muon, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from transformers import DataCollatorWithPadding\n",
    "from utils import remove_extra_brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./modern_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b446746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple CSV files\n",
    "df = datasets.load_dataset('csv', data_files={\n",
    "    'train': '../data/train.csv',\n",
    "    'test': '../data/test.csv'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861b02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only a small portion for quick testing\n",
    "df['train'] = df['train'].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model max length is 8192 characters.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "print(f\"Model max length is {tokenizer.model_max_length} characters.\")\n",
    "model_classification = AutoModelForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", num_labels=3)\n",
    "model_classification = model_classification.to(\"cuda\", torch.bfloat16)\n",
    "model_maskedLM = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ccd4c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202467ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dataset(row):\n",
    "    cleaned_prompt = remove_extra_brackets(row['prompt'])\n",
    "    cleaned_response_a = remove_extra_brackets(row['response_a'])\n",
    "    cleaned_response_b = remove_extra_brackets(row['response_b'])\n",
    "    \n",
    "    sep_id = tokenizer.sep_token_id\n",
    "    cls_id = tokenizer.cls_token_id\n",
    "    \n",
    "    p_ids = tokenizer(cleaned_prompt, add_special_tokens=False)['input_ids']\n",
    "    a_ids = tokenizer(cleaned_response_a, add_special_tokens=False)['input_ids']\n",
    "    b_ids = tokenizer(cleaned_response_b, add_special_tokens=False)['input_ids']\n",
    "    \n",
    "    # Structure: [CLS] + Prompt + [SEP] + A + [SEP] + B + [SEP]\n",
    "    input_ids = [cls_id] + p_ids + [sep_id] + a_ids + [sep_id] + b_ids + [sep_id]\n",
    "\n",
    "    \n",
    "    winner = [row['winner_model_a'], row['winner_model_b'], row['winner_tie']]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"winner\": winner,\n",
    "        \"length\": len(input_ids) # easy filtering later\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e22be4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:01<00:00, 539.16 examples/s]\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 111.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "df = df.map(fix_dataset, batched=False).remove_columns(['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b','winner_model_a', 'winner_model_b', 'winner_tie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fe0b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 1000/1000 [00:00<00:00, 44446.25 examples/s]\n",
      "Filter: 100%|██████████| 3/3 [00:00<00:00, 166.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "df = df.filter(lambda batch: np.array(batch[\"length\"]) <= 8192, batched=True).remove_columns([\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a108d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = df['train'].train_test_split(test_size=0.05, seed=42)\n",
    "df['train'] = train_val_split['train']\n",
    "df['validation'] = train_val_split['test']\n",
    "df = df.with_format(\"torch\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "train_dataloader = DataLoader(df[\"train\"], batch_size=4, shuffle=True, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(df[\"validation\"], batch_size=4, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bed61be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'winner'],\n",
       "        num_rows: 948\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'winner'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'winner'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ca7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = torch.compile(model_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0d37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 42/13631 [02:21<12:44:41,  3.38s/it, Prediction=[0, 1, 0, 0] | [0, 1, 0, 2]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     40\u001b[39m     loss = loss_fn(outputs, true_labels)\n\u001b[32m     42\u001b[39m (loss / GRADIENT_ACCUMULATION_STEPS).backward()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (step + \u001b[32m1\u001b[39m) % GRADIENT_ACCUMULATION_STEPS == \u001b[32m0\u001b[39m:\n\u001b[32m     47\u001b[39m     accuracy = \u001b[32m100\u001b[39m * (grad_steps_corrects / grad_steps_count)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model_classification.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "EPOCHS = 10\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "GRADIENT_ACCUMULATION_STEPS = 32\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "grad_steps_corrects = 0\n",
    "grad_steps_count = 0\n",
    "\n",
    "train_size = len(train_dataloader)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model_classification.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=True, position=0)\n",
    "    validation_bar = tqdm(val_dataloader, desc=f\"Validation {epoch+1}/{EPOCHS}\", leave=False, position=0)\n",
    "    for step, data in enumerate(train_bar):\n",
    "        data = {key: value.to(\"cuda\") for key, value in data.items()}\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "            outputs = model_classification(data[\"input_ids\"], attention_mask=data[\"attention_mask\"]).logits\n",
    "            with torch.no_grad():\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, true_labels = torch.max(data[\"winner\"], 1)\n",
    "                examples_count = data[\"input_ids\"].size(0)\n",
    "                correct_count = (predicted == true_labels).sum().item()\n",
    "                grad_steps_count += examples_count\n",
    "                total_count += examples_count\n",
    "                total_correct += correct_count\n",
    "                grad_steps_corrects += correct_count\n",
    "                if (step+1) % 10 == 0:\n",
    "                    train_bar.set_postfix({'Prediction': f\"{predicted.cpu().tolist()} | {true_labels.cpu().tolist()}\"})\n",
    "                \n",
    "            \n",
    "            loss = loss_fn(outputs, true_labels)\n",
    "        \n",
    "        (loss / GRADIENT_ACCUMULATION_STEPS).backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "            \n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            accuracy = 100 * (grad_steps_corrects / grad_steps_count)\n",
    "            grad_steps_corrects = 0\n",
    "            grad_steps_count = 0\n",
    "            \n",
    "            train_bar.set_postfix({'accuracy': f\"{(accuracy):.2f}%\"})\n",
    "            # torch.nn.utils.clip_grad_norm_(model_classification.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            writer.add_scalar('Accuracy/train', accuracy, (epoch * train_size) + (step + 1))\n",
    "        \n",
    "            \n",
    "        if step % 4000 == 0 and step != 0:\n",
    "            model_classification.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for val_data in validation_bar:\n",
    "                    val_data = {key: value.to(\"cuda\") for key, value in val_data.items()}\n",
    "                    outputs = model_classification(val_data[\"input_ids\"], attention_mask=val_data[\"attention_mask\"]).logits\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    _, true_labels = torch.max(val_data[\"winner\"], 1)\n",
    "                    total += true_labels.size(0)\n",
    "                    correct += (predicted == true_labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * (correct / total)\n",
    "            print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "            writer.add_scalar('Accuracy/validation', accuracy, (epoch * train_size) + (step + 1))\n",
    "            model_classification.train()\n",
    "    \n",
    "    \n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Avg Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Training Accuracy: {100 * (total_correct / total_count):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_preference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
