{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e375f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "import bitsandbytes as bnb\n",
    "import loralib as lora\n",
    "import numpy as np\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import torch\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils import CLASSIFICATION_PROMPT, remove_extra_brackets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import CrossEntropyLoss, Linear\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f670629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model max length is 1010000 characters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740d3a2bf13c47cfbb652c0f652356db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-4B-Instruct-2507 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B-Instruct-2507\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(f\"Model max length is {tokenizer.model_max_length} characters.\")\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "    device_map=\"cuda\",\n",
    "    num_labels=3,\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    modules_to_save=[\"score\"],\n",
    ")\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "lora.mark_only_lora_as_trainable(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b115c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./best_qwen_llm_finetune_model.pth\"), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0af796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./finetuned_qwen_llm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8470c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple CSV files\n",
    "df = datasets.load_dataset(\n",
    "    \"csv\", data_files={\"train\": \"../data/train.csv\", \"test\": \"../data/test.csv\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d15775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['train'].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6800f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dataset(row):\n",
    "    cleaned_prompt = remove_extra_brackets(row[\"prompt\"])\n",
    "    cleaned_response_a = remove_extra_brackets(row[\"response_a\"])\n",
    "    cleaned_response_b = remove_extra_brackets(row[\"response_b\"])\n",
    "\n",
    "    full_prompt = CLASSIFICATION_PROMPT.format(\n",
    "        prompt=cleaned_prompt,\n",
    "        response_a=cleaned_response_a,\n",
    "        response_b=cleaned_response_b,\n",
    "    )\n",
    "\n",
    "    tokenized = tokenizer(full_prompt)\n",
    "\n",
    "    winner = [row[\"winner_model_a\"], row[\"winner_model_b\"], row[\"winner_tie\"]]\n",
    "\n",
    "    return {**tokenized, \"winner\": winner, \"length\": len(tokenized[\"input_ids\"])}\n",
    "\n",
    "df = df.map(fix_dataset, batched=False).remove_columns(\n",
    "    [\n",
    "        \"id\",\n",
    "        \"model_a\",\n",
    "        \"model_b\",\n",
    "        \"prompt\",\n",
    "        \"response_a\",\n",
    "        \"response_b\",\n",
    "        \"winner_model_a\",\n",
    "        \"winner_model_b\",\n",
    "        \"winner_tie\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = df.filter(\n",
    "    lambda batch: np.array(batch[\"length\"]) <= 12000, batched=True\n",
    ").remove_columns([\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6444c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_format(\"torch\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084210db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    df, batch_size=2, shuffle=False, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5fc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = CrossEntropyLoss()\n",
    "# total_loss = 0\n",
    "# total_correct = 0\n",
    "# total_count = 0\n",
    "# for data in tqdm(dataloader):\n",
    "#     with torch.no_grad():\n",
    "#         with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "#             data = {\n",
    "#                 key: value.to(\"cuda\") for key, value in data.items()\n",
    "#             }\n",
    "#             outputs = model(data[\"input_ids\"]).logits\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             _, true_labels = torch.max(data[\"winner\"], 1)\n",
    "#             total_loss += loss_fn(outputs, true_labels).item()\n",
    "#             total_count += true_labels.size(0)\n",
    "#             total_correct += (predicted == true_labels).sum().item()\n",
    "\n",
    "# accuracy = 100 * (total_correct / total_count)\n",
    "# print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "# print(f\"Validation Loss: {total_loss:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b7193a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login, HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ed24c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918774ec61f74901930146ebadd53492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd569256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d13a11cdba44939973aebbdb3609f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17398fea9351432b8a6ecdb1b7fa4e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5472f5e181e94a74828def2cbea67168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cda9e8fa6e04351ab7db93ae76d8417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a70a7f9d7a463682dfa65d0e9981bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Vmpletsos/qwen3-4b-merged-preference-classifier/commit/b8b89eb832405c75c41711468b68aa65df6384f6', commit_message='Upload tokenizer', commit_description='', oid='b8b89eb832405c75c41711468b68aa65df6384f6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Vmpletsos/qwen3-4b-merged-preference-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='Vmpletsos/qwen3-4b-merged-preference-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge LoRA weights into the base model\n",
    "# model = model.merge_and_unload()\n",
    "\n",
    "# Now push the full merged model\n",
    "model.push_to_hub(\"Vmpletsos/qwen3-4b-merged-preference-classifier\")\n",
    "tokenizer.push_to_hub(\"Vmpletsos/qwen3-4b-merged-preference-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e4c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
